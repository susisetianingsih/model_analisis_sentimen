## âœ¨ Project Descriptions 

<p>This project is a project resulting from PKM-RE. In the project development process, the model implementation is built in the form of a website to make it easier to use. Semilu24 is a project built using the Streamlite framework.This website is capable of training models, use the best model, validation for model, and classifying the sentiments of 2024 presidential candidates.</p> 

## ğŸ§  Problem Solving Concept
<p>In short, there are three stages, namely data crawling, data processing, and modeling.</p>

âœï¸ **Data Crawling**
<p>Data crawling is the process of collecting tweet data. This process is carried out using a python script using the API from Twitter.</p>

âš™ï¸ **Data Processing**
<p>Data processing is a process for cleaning data so that it can be used in modeling. This process is carried out through five stages, namely Cleansing, CaseFolding, Stemming, Tokenizing, and Filtering.</p>

ğŸ¤– **Modeling**
<p>modeling is the process of creating a model to be able to carry out sentiment classification. The model that I use in this sentiment classification is the Naive Bayes classifier.</p>

## ğŸ“‘ Requirement
**Data:** Tweet Data is used to model building.

## ğŸ‘©â€ğŸ’» System Development
<p>Tools used in creating the system include:</p>

A. **Development environtment:** Google Collaboratory was used to provide model creation.

B. **Database:** Google Drive is used to database management tool like saving an employee data file.

C. **Programming Language:** Python is used to train the classification model.

