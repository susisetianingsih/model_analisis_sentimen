{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC5MmdYqBebG",
        "outputId": "31ce0056-9ce6-481b-c041-af45a9dc171e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdo7JIepZxJn"
      },
      "source": [
        "# KODE BARU DAN BERFUNGSI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3shAVaM5Ul5W"
      },
      "source": [
        "## import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaF6073UZ2Vc",
        "outputId": "fe07e729-81c6-4d28-d8f3-d6d09ecdff56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,059 kB]\n",
            "Get:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [23.8 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,325 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,676 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,390 kB]\n",
            "Get:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [66.2 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,671 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,713 kB]\n",
            "Fetched 9,156 kB in 2s (4,367 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20230311ubuntu0.22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.15).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "gnupg set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 81 not upgraded.\n",
            "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_20.x nodistro main\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Get:6 https://deb.nodesource.com/node_20.x nodistro InRelease [12.1 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://deb.nodesource.com/node_20.x nodistro/main amd64 Packages [4,820 B]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 17.0 kB in 1s (13.4 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 81 not upgraded.\n",
            "Need to get 26.1 MB of archives.\n",
            "After this operation, 163 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_20.x nodistro/main amd64 nodejs amd64 20.11.0-1nodesource1 [26.1 MB]\n",
            "Fetched 26.1 MB in 1s (39.5 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 121671 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_20.11.0-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (20.11.0-1nodesource1) ...\n",
            "Setting up nodejs (20.11.0-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "v20.11.0\n"
          ]
        }
      ],
      "source": [
        "# Import required Python package\n",
        "!pip install pandas\n",
        "\n",
        "# Install Node.js (because tweet-harvest built using Node.js)\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y ca-certificates curl gnupg\n",
        "!sudo mkdir -p /etc/apt/keyrings\n",
        "!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg\n",
        "\n",
        "!NODE_MAJOR=20 && echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main\" | sudo tee /etc/apt/sources.list.d/nodesource.list\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install nodejs -y\n",
        "\n",
        "!node -v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBoAKUwPcV4F"
      },
      "source": [
        "## **Crawl Data**  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epu7hZ9svUKg"
      },
      "source": [
        "\n",
        "KALO DI RUN, OUTPUTNYA MUNCUL \"? What's your Twitter auth token?\", KLIK DISAMPINGNYA TERUS MASUKIN TOKEN AUTH-NYA\n",
        "\n",
        "TOKEN AUTH DI PEROLEH DARI MANA?\n",
        "\n",
        "1.   CARANYA BUKA BROWSER DAN MASUK KE TWITTER\n",
        "2.   BUKA INSPECT TERUS PILIH \"APPLICATION\" DI MENUMYA\n",
        "3.   PILIH \"Cookies\" DAN KLIK \"https://twitter.com\"\n",
        "4.   TERAKHIR PILIH \"auth_token\" DI TABEL LALU COPY VALUE DAN PASTE KE YANG MINTA TOKEN AUTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXNSZDGncddL"
      },
      "outputs": [],
      "source": [
        "# Masukan token API\n",
        "twitter_auth_token = \"4f6d376881e2ee6470d8d62b0fa1344a83439ca7\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Twn-4KccTxt",
        "outputId": "d103c24c-2761-4c39-fc26-eedb9b80bcab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\u001b[1m\u001b[22m\n",
            "\u001b[1mWelcome to the Twitter Crawler üï∑Ô∏è\u001b[22m\n",
            "\u001b[1m\u001b[22m\n",
            "This script uses Chromium Browser to crawl data from Twitter with *your* Twitter auth token.\n",
            "Please enter your Twitter auth token when prompted.\n",
            "\n",
            "Note: Keep your access token secret! Don't share it with anyone else.\n",
            "Note: This script only runs on your local device.\n",
            "\n",
            "\u001b[K\u001b[?25h\n",
            "added 3 packages in 1s\n",
            "Installing dependencies...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://deb.nodesource.com/node_20.x nodistro InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libasound2 set to manually installed.\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk-bridge2.0-0 set to manually installed.\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatk1.0-0 set to manually installed.\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libatspi2.0-0 set to manually installed.\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libcairo2 set to manually installed.\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libfontconfig1 set to manually installed.\n",
            "libnspr4 is already the newest version (2:4.32-3build1).\n",
            "libnspr4 set to manually installed.\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcb1 set to manually installed.\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxcomposite1 set to manually installed.\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxdamage1 set to manually installed.\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxfixes3 set to manually installed.\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxkbcommon0 set to manually installed.\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "libxrandr2 set to manually installed.\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.7).\n",
            "libcups2 set to manually installed.\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdbus-1-3 set to manually installed.\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libdrm2 set to manually installed.\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.2).\n",
            "libfreetype6 set to manually installed.\n",
            "libgbm1 is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
            "libgbm1 set to manually installed.\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.2).\n",
            "libglib2.0-0 set to manually installed.\n",
            "libnss3 is already the newest version (2:3.68.2-0ubuntu1.2).\n",
            "libnss3 set to manually installed.\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpango-1.0-0 set to manually installed.\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwayland-client0 set to manually installed.\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-6 set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-encodings xfonts-utils xserver-common\n",
            "Recommended packages:\n",
            "  fonts-ipafont-mincho fonts-tlwg-loma xfonts-base\n",
            "The following NEW packages will be installed:\n",
            "  fonts-freefont-ttf fonts-ipafont-gothic fonts-noto-color-emoji fonts-tlwg-loma-otf fonts-unifont\n",
            "  fonts-wqy-zenhei libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-cyrillic xfonts-encodings\n",
            "  xfonts-scalable xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 16 newly installed, 0 to remove and 81 not upgraded.\n",
            "Need to get 29.6 MB of archives.\n",
            "After this operation, 71.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ipafont-gothic all 00303-21ubuntu1 [3,513 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.042-0ubuntu0.22.04.1 [9,944 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-tlwg-loma-otf all 1:0.7.3-1 [107 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-unifont all 1:14.0.01-1 [3,551 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-wqy-zenhei all 0.9.45-8 [7,472 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 xfonts-cyrillic all 1:1.0.5 [386 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-scalable all 1:1.0.3-1.2ubuntu1 [306 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.7 [28.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.7 [865 kB]\n",
            "Fetched 29.6 MB in 2s (19.6 MB/s)\n",
            "Selecting previously unselected package fonts-ipafont-gothic.\n",
            "(Reading database ... 126924 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-ipafont-gothic_00303-21ubuntu1_all.deb ...\n",
            "Unpacking fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../01-fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
            "Selecting previously unselected package fonts-noto-color-emoji.\n",
            "Preparing to unpack .../02-fonts-noto-color-emoji_2.042-0ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking fonts-noto-color-emoji (2.042-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package fonts-tlwg-loma-otf.\n",
            "Preparing to unpack .../03-fonts-tlwg-loma-otf_1%3a0.7.3-1_all.deb ...\n",
            "Unpacking fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
            "Selecting previously unselected package fonts-unifont.\n",
            "Preparing to unpack .../04-fonts-unifont_1%3a14.0.01-1_all.deb ...\n",
            "Unpacking fonts-unifont (1:14.0.01-1) ...\n",
            "Selecting previously unselected package fonts-wqy-zenhei.\n",
            "Preparing to unpack .../05-fonts-wqy-zenhei_0.9.45-8_all.deb ...\n",
            "Unpacking fonts-wqy-zenhei (0.9.45-8) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../06-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../07-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../08-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../09-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../10-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../11-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-cyrillic.\n",
            "Preparing to unpack .../12-xfonts-cyrillic_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-cyrillic (1:1.0.5) ...\n",
            "Selecting previously unselected package xfonts-scalable.\n",
            "Preparing to unpack .../13-xfonts-scalable_1%3a1.0.3-1.2ubuntu1_all.deb ...\n",
            "Unpacking xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../14-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.7_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../15-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.7_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Setting up fonts-noto-color-emoji (2.042-0ubuntu0.22.04.1) ...\n",
            "Setting up fonts-wqy-zenhei (0.9.45-8) ...\n",
            "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
            "update-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up fonts-unifont (1:14.0.01-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-cyrillic (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Setting up xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.7) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Downloading Chromium 121.0.6167.57 (playwright build v1097)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1097/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G152.8 MiB [] 0% 0.0s\u001b[0K\u001b[1G152.8 MiB [] 0% 15.1s\u001b[0K\u001b[1G152.8 MiB [] 0% 7.7s\u001b[0K\u001b[1G152.8 MiB [] 0% 4.9s\u001b[0K\u001b[1G152.8 MiB [] 1% 3.9s\u001b[0K\u001b[1G152.8 MiB [] 2% 3.3s\u001b[0K\u001b[1G152.8 MiB [] 2% 3.4s\u001b[0K\u001b[1G152.8 MiB [] 3% 3.4s\u001b[0K\u001b[1G152.8 MiB [] 4% 3.1s\u001b[0K\u001b[1G152.8 MiB [] 4% 3.2s\u001b[0K\u001b[1G152.8 MiB [] 4% 3.1s\u001b[0K\u001b[1G152.8 MiB [] 5% 3.1s\u001b[0K\u001b[1G152.8 MiB [] 6% 3.0s\u001b[0K\u001b[1G152.8 MiB [] 7% 2.9s\u001b[0K\u001b[1G152.8 MiB [] 7% 2.8s\u001b[0K\u001b[1G152.8 MiB [] 8% 2.8s\u001b[0K\u001b[1G152.8 MiB [] 9% 2.7s\u001b[0K\u001b[1G152.8 MiB [] 9% 2.8s\u001b[0K\u001b[1G152.8 MiB [] 10% 2.7s\u001b[0K\u001b[1G152.8 MiB [] 11% 2.6s\u001b[0K\u001b[1G152.8 MiB [] 12% 2.5s\u001b[0K\u001b[1G152.8 MiB [] 13% 2.5s\u001b[0K\u001b[1G152.8 MiB [] 14% 2.4s\u001b[0K\u001b[1G152.8 MiB [] 15% 2.4s\u001b[0K\u001b[1G152.8 MiB [] 16% 2.3s\u001b[0K\u001b[1G152.8 MiB [] 17% 2.3s\u001b[0K\u001b[1G152.8 MiB [] 19% 2.1s\u001b[0K\u001b[1G152.8 MiB [] 20% 2.0s\u001b[0K\u001b[1G152.8 MiB [] 21% 1.9s\u001b[0K\u001b[1G152.8 MiB [] 23% 1.8s\u001b[0K\u001b[1G152.8 MiB [] 25% 1.7s\u001b[0K\u001b[1G152.8 MiB [] 26% 1.6s\u001b[0K\u001b[1G152.8 MiB [] 27% 1.6s\u001b[0K\u001b[1G152.8 MiB [] 28% 1.6s\u001b[0K\u001b[1G152.8 MiB [] 29% 1.6s\u001b[0K\u001b[1G152.8 MiB [] 30% 1.5s\u001b[0K\u001b[1G152.8 MiB [] 31% 1.5s\u001b[0K\u001b[1G152.8 MiB [] 32% 1.5s\u001b[0K\u001b[1G152.8 MiB [] 33% 1.4s\u001b[0K\u001b[1G152.8 MiB [] 34% 1.4s\u001b[0K\u001b[1G152.8 MiB [] 35% 1.3s\u001b[0K\u001b[1G152.8 MiB [] 37% 1.3s\u001b[0K\u001b[1G152.8 MiB [] 38% 1.3s\u001b[0K\u001b[1G152.8 MiB [] 39% 1.2s\u001b[0K\u001b[1G152.8 MiB [] 40% 1.2s\u001b[0K\u001b[1G152.8 MiB [] 42% 1.1s\u001b[0K\u001b[1G152.8 MiB [] 43% 1.1s\u001b[0K\u001b[1G152.8 MiB [] 44% 1.1s\u001b[0K\u001b[1G152.8 MiB [] 45% 1.1s\u001b[0K\u001b[1G152.8 MiB [] 47% 1.0s\u001b[0K\u001b[1G152.8 MiB [] 48% 1.0s\u001b[0K\u001b[1G152.8 MiB [] 49% 1.0s\u001b[0K\u001b[1G152.8 MiB [] 50% 1.0s\u001b[0K\u001b[1G152.8 MiB [] 51% 0.9s\u001b[0K\u001b[1G152.8 MiB [] 52% 0.9s\u001b[0K\u001b[1G152.8 MiB [] 53% 0.9s\u001b[0K\u001b[1G152.8 MiB [] 54% 0.9s\u001b[0K\u001b[1G152.8 MiB [] 55% 0.8s\u001b[0K\u001b[1G152.8 MiB [] 57% 0.8s\u001b[0K\u001b[1G152.8 MiB [] 58% 0.8s\u001b[0K\u001b[1G152.8 MiB [] 59% 0.7s\u001b[0K\u001b[1G152.8 MiB [] 61% 0.7s\u001b[0K\u001b[1G152.8 MiB [] 62% 0.7s\u001b[0K\u001b[1G152.8 MiB [] 63% 0.6s\u001b[0K\u001b[1G152.8 MiB [] 65% 0.6s\u001b[0K\u001b[1G152.8 MiB [] 67% 0.6s\u001b[0K\u001b[1G152.8 MiB [] 68% 0.5s\u001b[0K\u001b[1G152.8 MiB [] 69% 0.5s\u001b[0K\u001b[1G152.8 MiB [] 70% 0.5s\u001b[0K\u001b[1G152.8 MiB [] 71% 0.5s\u001b[0K\u001b[1G152.8 MiB [] 72% 0.5s\u001b[0K\u001b[1G152.8 MiB [] 73% 0.5s\u001b[0K\u001b[1G152.8 MiB [] 74% 0.4s\u001b[0K\u001b[1G152.8 MiB [] 75% 0.4s\u001b[0K\u001b[1G152.8 MiB [] 76% 0.4s\u001b[0K\u001b[1G152.8 MiB [] 78% 0.4s\u001b[0K\u001b[1G152.8 MiB [] 79% 0.4s\u001b[0K\u001b[1G152.8 MiB [] 80% 0.3s\u001b[0K\u001b[1G152.8 MiB [] 82% 0.3s\u001b[0K\u001b[1G152.8 MiB [] 83% 0.3s\u001b[0K\u001b[1G152.8 MiB [] 84% 0.3s\u001b[0K\u001b[1G152.8 MiB [] 85% 0.2s\u001b[0K\u001b[1G152.8 MiB [] 87% 0.2s\u001b[0K\u001b[1G152.8 MiB [] 89% 0.2s\u001b[0K\u001b[1G152.8 MiB [] 91% 0.1s\u001b[0K\u001b[1G152.8 MiB [] 92% 0.1s\u001b[0K\u001b[1G152.8 MiB [] 93% 0.1s\u001b[0K\u001b[1G152.8 MiB [] 94% 0.1s\u001b[0K\u001b[1G152.8 MiB [] 95% 0.1s\u001b[0K\u001b[1G152.8 MiB [] 96% 0.1s\u001b[0K\u001b[1G152.8 MiB [] 97% 0.0s\u001b[0K\u001b[1G152.8 MiB [] 98% 0.0s\u001b[0K\u001b[1G152.8 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 121.0.6167.57 (playwright build v1097) downloaded to /root/.cache/ms-playwright/chromium-1097\n",
            "Downloading FFMPEG playwright build v1009\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1009/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.6 MiB [] 7% 0.2s\u001b[0K\u001b[1G2.6 MiB [] 31% 0.1s\u001b[0K\u001b[1G2.6 MiB [] 59% 0.0s\u001b[0K\u001b[1G2.6 MiB [] 99% 0.0s\u001b[0K\u001b[1G2.6 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1009 downloaded to /root/.cache/ms-playwright/ffmpeg-1009\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mOpening twitter search page...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[33mFilling in keywords: anies lang:id until:2023-12-14 since:2023-12-08\u001b[39m\n",
            "\u001b[33m\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 15\u001b[39m\n",
            "\u001b[90mScrolling more...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 30\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 44\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 59\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 73\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 87\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 102\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 118\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 133\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 148\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 156\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 174\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 188\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 204\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 221\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 236\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 249\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 260\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 279\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 294\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 309\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 326\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 343\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 363\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 381\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 396\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 413\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 430\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 445\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 463\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 478\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 495\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 514\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 530\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 547\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 563\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 578\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 598\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 616\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 631\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 651\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 669\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 688\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 704\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 720\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 737\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 755\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 773\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 791\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 807\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@11e706811ca24b9e1d2e4f0b2ca36b55\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@2186ef19a3b46421bae2e15df9f99369\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@1297f37a7f1c29420506d858e6c224bb\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@764264591919bb3a942bb273cc64ed6b\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@83e76425a62ff85d3be2e241e7e20294\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@89f19dfcce413b281868a19721f67dbc\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@80cc0621a941ff5a552e52d77331b425\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@f171868ba7c4bfa89368b8deec22425b\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@ad1b5128512411db151868938274245e\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@750ccb0ef60da09b581691b0607e1ec8\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "Error parsing response json: {\"_type\":\"Response\",\"_guid\":\"response@5e992dbcf347ab227a5fd400b8793086\"}\n",
            "Most likely, you have already exceeded the Twitter rate limit. Read more on https://twitter.com/elonmusk/status/1675187969420828672?s=46.\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 824\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 840\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 856\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 873\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 890\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 907\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 922\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 934\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 947\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 961\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 977\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 990\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1005\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1021\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1036\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1049\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1067\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1085\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1100\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1115\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1130\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1145\u001b[39m\n",
            "\u001b[90m\u001b[39m\n",
            "\u001b[90m--Taking a break, waiting for 10 seconds...\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1160\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1177\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1193\u001b[39m\n",
            "\u001b[34m\u001b[39m\n",
            "\u001b[34mGot some tweets, saving to file...\u001b[39m\n",
            "\u001b[34mYour tweets saved to: /content/tweets-data/anies_Desember_M2.csv\u001b[39m\n",
            "\u001b[33mTotal tweets saved: 1210\u001b[39m\n",
            "Already got 1210 tweets, done scrolling...\n",
            "\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m New \u001b[33mminor\u001b[39m version of npm available! \u001b[31m10.2.4\u001b[39m -> \u001b[32m10.4.0\u001b[39m\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Changelog: \u001b[36mhttps://github.com/npm/cli/releases/tag/v10.4.0\u001b[39m\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m Run \u001b[32mnpm install -g npm@10.4.0\u001b[39m to update!\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[36;40mnotice\u001b[0m\u001b[35m\u001b[0m \n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Crawl Data\n",
        "filename = 'anies_Desember_M2.csv'\n",
        "search_keyword = 'anies lang:id until:2023-12-14 since:2023-12-08'\n",
        "limit = 1200\n",
        "\n",
        "!npx --yes tweet-harvest@2.2.8 -o \"{filename}\" -s \"{search_keyword}\" -l {limit} --token {twitter_auth_token}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei9Jzk1mdUdZ"
      },
      "source": [
        "## Buat Liat Datanya (terserah mau dijalankan atau engga)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au2pF_zodTdh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "file_path = f\"tweets-data/{filename}\"\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(file_path, delimiter=\";\")\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK8p-d5RdXac"
      },
      "outputs": [],
      "source": [
        "# Cek jumlah data yang didapatkan\n",
        "\n",
        "num_tweets = len(df)\n",
        "print(f\"Jumlah tweet dalam dataframe adalah {num_tweets}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw6TLtx3Z3xF"
      },
      "source": [
        "# KODE LAMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrC6ITzln2Tm",
        "outputId": "7f545ae6-07c2-4843-917c-5e3b0c511a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-thrhbcz5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git /tmp/pip-req-build-thrhbcz5\n",
            "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit 614d4c2029a62d348ca56598f87c425966aaec66\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (2.27.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (3.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->snscrape==0.7.0.20230622) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.7.1)\n",
            "Building wheels for collected packages: snscrape\n",
            "  Building wheel for snscrape (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for snscrape: filename=snscrape-0.7.0.20230622-py3-none-any.whl size=74814 sha256=e9344043bf1293cd549ab857710a33808147e3ee91b954006849b1d4f557dc18\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fthc9cgu/wheels/05/e9/f7/57056e7c7e44b1feed932fa49fdec9d706c4f563e37160ab74\n",
            "Successfully built snscrape\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.7.0.20230622\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "# !pip install textblob\n",
        "# !pip install openpyxl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UqanOr2i5jH"
      },
      "source": [
        "## Algoritma 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOX9ZPHcqZNF"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "since_date = '2023-06-16'\n",
        "until_date = '2023-06-20'\n",
        "\n",
        "query = 'prabowo subianto since:{} until:{}'.format(since_date, until_date)\n",
        "\n",
        "tweets_list = []\n",
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query + 'lang:id').get_items()):\n",
        "  if i > 1000:\n",
        "    break\n",
        "  tweets_list.append([tweet.date, tweet.user.username, tweet.rawContent])\n",
        "\n",
        "tweets_df2 = pd.DataFrame(tweets_list, columns=['Datetime', 'Username', 'Text'])\n",
        "print(tweets_df2)\n",
        "tweets_df2.to_csv(\"prabowoMinggu1.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uBzfpZjjCJR"
      },
      "source": [
        "## Algoritma 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfIYFCUEzsa1"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "# Creating list to append tweet data to\n",
        "tweets_list2 = []\n",
        "\n",
        "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('prabowo since:2023-06-16 until:2023-06-20' + 'lang:id').get_items()):\n",
        "    if i>1000:\n",
        "        break\n",
        "    tweets_list2.append([tweet.date, tweet.user.username, tweet.content])\n",
        "\n",
        "# Creating a dataframe from the tweets list above\n",
        "tweets_df2 = pd.DataFrame(tweets_list2, columns=['Datetime', 'Username', 'Text'])\n",
        "print(tweets_df2)\n",
        "tweets_df2.to_csv(\"prabowoSMinggu1.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s90ccpmnv2U9"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "query = \"prabowo since:2023-06-16 until:2023-06-20\"\n",
        "tweets = []\n",
        "limit = 1000\n",
        "\n",
        "scraper = sntwitter.TwitterSearchScraper(query + 'lang: id')\n",
        "for tweet in scraper.get_items():\n",
        "  # print(vars(tweet))\n",
        "  # break\n",
        "  if len(tweets) == limit:\n",
        "    break\n",
        "  else:\n",
        "    tweets.append([tweet.date, tweet.user.username, tweet.content])\n",
        "\n",
        "df = pd.DataFrame(tweets, columns = ['Date', 'User', 'Tweet'])\n",
        "print(df)\n",
        "df.to_csv(\"prabowoSubMinggu1.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1MO5hUgEgGQ"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "\n",
        "since_date = '2023-06-16'\n",
        "until_date = '2023-06-20'\n",
        "\n",
        "query = 'prabowo subianto since:{} until:{}'.format(since_date, until_date)\n",
        "\n",
        "tweets_list = []\n",
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query + ' lang:id').get_items()):\n",
        "    if i > 1000:\n",
        "        break\n",
        "    tweets_list.append([tweet.date, tweet.user.username, tweet.content])\n",
        "\n",
        "tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Username', 'Text'])\n",
        "print(tweets_df)\n",
        "tweets_df.to_csv(\"prabowoMinggu1.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSaLo3hGEe_Y"
      },
      "source": [
        "# Algoritma Chat GPT Maria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdT753DboZow"
      },
      "source": [
        "## API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk7_Ic8ARg4S"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import csv\n",
        "\n",
        "# Mengisi API key dan token Twitter\n",
        "consumer_key = 'wrFeds5bm26mgTuA3NcEfTDX2'\n",
        "consumer_secret = 'yc1xIPl7wZZSYYbzmoE72uEGK1ekA1gkEmkFtisyp6mpcit2VM'\n",
        "access_token = 'd5fb709132ec1641feb245a1d9f6d3bd5c8e0435'\n",
        "access_token_secret = 'UbGxV1KgCAlc22fGI2febtfvLgNjwF0H8crFv2vdzei5z'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDLuDH5bRjIj"
      },
      "source": [
        "## Minggu **1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "s8CFgBSl_bqu",
        "outputId": "1f4add51-6433-422d-ce89-4a72698069cf"
      },
      "outputs": [
        {
          "ename": "Unauthorized",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3262ad70a8e9>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tanggal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Username'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             model = ModelParser().parse(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m_Twitter\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \"\"\"\n\u001b[0;32m-> 1309\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             'GET', 'search/tweets', endpoint_parameters=(\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geocode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'locale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mBadRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnauthorized\u001b[0m: 401 Unauthorized\n89 - Invalid or expired token."
          ]
        }
      ],
      "source": [
        "# Mengotentikasi dengan Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Kata kunci dan rentang waktu yang ingin dicari\n",
        "keyword = 'prabowo 2024 until:2023-05-07 since:2023-05-01 -filter:retweets'\n",
        "\n",
        "# Jumlah tweet yang ingin diambil\n",
        "tweet_count = 250\n",
        "\n",
        "# Melakukan crawling\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang='id', tweet_mode='extended').items(tweet_count)\n",
        "\n",
        "# Menyimpan hasil crawling ke dalam file CSV\n",
        "with open('prabowoMeiMinggu1.csv', 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Tanggal', 'Username', 'Tweet'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        writer.writerow([tweet.created_at, tweet.user.screen_name, tweet.full_text])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwTFjQXHoc0T"
      },
      "source": [
        "## Minggu 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4TnVSJOoeW7"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import csv\n",
        "\n",
        "# Mengisi API key dan token Twitter\n",
        "consumer_key = 'DqsKCoLOziEpR3OMH5Y8oiz7c'\n",
        "consumer_secret = 'OHljrypY8YoxqQhvqj0PZAir379j8VUHBvvC5KMiqrJnQtpq9V'\n",
        "access_token = '1561941875782610944-2c3p2Fn97uatF6NnmDmD9HLD4vtr8T'\n",
        "access_token_secret = 'UbGxV1KgCAlc22fGI2febtfvLgNjwF0H8crFv2vdzei5z'\n",
        "\n",
        "\n",
        "# Mengotentikasi dengan Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Kata kunci dan rentang waktu yang ingin dicari\n",
        "keyword = 'anies 2024 -filter:retweets since:2023-06-08 until:2023-06-14'\n",
        "\n",
        "# Jumlah tweet yang ingin diambil\n",
        "tweet_count = 1000\n",
        "\n",
        "# Melakukan crawling\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang='id', tweet_mode='extended').items(tweet_count)\n",
        "\n",
        "# Menyimpan hasil crawling ke dalam file CSV\n",
        "with open('aniesjaya.csv', 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Username', 'Tweet', 'Tanggal'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        writer.writerow([tweet.user.screen_name, tweet.full_text, tweet.created_at])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTgntuEro3wF"
      },
      "source": [
        "## Minggu 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-U8g42xo5Vq"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import csv\n",
        "\n",
        "# Mengisi API key dan token Twitter\n",
        "consumer_key = 'DqsKCoLOziEpR3OMH5Y8oiz7c'\n",
        "consumer_secret = 'OHljrypY8YoxqQhvqj0PZAir379j8VUHBvvC5KMiqrJnQtpq9V'\n",
        "access_token = '1561941875782610944-2c3p2Fn97uatF6NnmDmD9HLD4vtr8T'\n",
        "access_token_secret = 'UbGxV1KgCAlc22fGI2febtfvLgNjwF0H8crFv2vdzei5z'\n",
        "\n",
        "\n",
        "# Mengotentikasi dengan Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Kata kunci dan rentang waktu yang ingin dicari\n",
        "keyword = 'anies 2024 -filter:retweets since:2023-06-01 until:2023-06-30'\n",
        "\n",
        "# Jumlah tweet yang ingin diambil\n",
        "tweet_count = 1000\n",
        "\n",
        "# Melakukan crawling\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang='id', tweet_mode='extended').items(tweet_count)\n",
        "\n",
        "# Menyimpan hasil crawling ke dalam file CSV\n",
        "with open('aniesjaya.csv', 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Username', 'Tweet', 'Tanggal'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        writer.writerow([tweet.user.screen_name, tweet.full_text, tweet.created_at])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-wxw2voo6W_"
      },
      "source": [
        "## Minggu 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrB3ME_to8-7"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import csv\n",
        "\n",
        "# Mengisi API key dan token Twitter\n",
        "consumer_key = 'DqsKCoLOziEpR3OMH5Y8oiz7c'\n",
        "consumer_secret = 'OHljrypY8YoxqQhvqj0PZAir379j8VUHBvvC5KMiqrJnQtpq9V'\n",
        "access_token = '1561941875782610944-2c3p2Fn97uatF6NnmDmD9HLD4vtr8T'\n",
        "access_token_secret = 'UbGxV1KgCAlc22fGI2febtfvLgNjwF0H8crFv2vdzei5z'\n",
        "\n",
        "\n",
        "# Mengotentikasi dengan Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Kata kunci dan rentang waktu yang ingin dicari\n",
        "keyword = 'anies 2024 -filter:retweets since:2023-06-01 until:2023-06-30'\n",
        "\n",
        "# Jumlah tweet yang ingin diambil\n",
        "tweet_count = 1000\n",
        "\n",
        "# Melakukan crawling\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang='id', tweet_mode='extended').items(tweet_count)\n",
        "\n",
        "# Menyimpan hasil crawling ke dalam file CSV\n",
        "with open('aniesjaya.csv', 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Username', 'Tweet', 'Tanggal'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        writer.writerow([tweet.user.screen_name, tweet.full_text, tweet.created_at])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1QhqVhVuizo"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import csv\n",
        "\n",
        "# Mengisi API key dan token Twitter\n",
        "consumer_key = 'DqsKCoLOziEpR3OMH5Y8oiz7c'\n",
        "consumer_secret = 'OHljrypY8YoxqQhvqj0PZAir379j8VUHBvvC5KMiqrJnQtpq9V'\n",
        "access_token = '1561941875782610944-2c3p2Fn97uatF6NnmDmD9HLD4vtr8T'\n",
        "access_token_secret = 'UbGxV1KgCAlc22fGI2febtfvLgNjwF0H8crFv2vdzei5z'\n",
        "\n",
        "# Mengotentikasi dengan Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Kata kunci dan rentang waktu yang ingin dicari\n",
        "keyword = 'anies 2024 -filter:retweets from:2023-06-01 until:2023-06-31'\n",
        "\n",
        "# Jumlah tweet yang ingin diambil\n",
        "tweet_count = 1000\n",
        "\n",
        "# Melakukan crawling\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang='id', tweet_mode='extended').items(tweet_count)\n",
        "\n",
        "# Menyimpan hasil crawling ke dalam file CSV\n",
        "with open('anis24.csv', 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Username', 'Tweet', 'Tanggal'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        writer.writerow([tweet.user.screen_name, tweet.full_text, tweet.created_at])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X86CvqHCENuW",
        "outputId": "feba8f0e-d51a-4d94-8c40-740592f6b451"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: start_datetime\n",
            "WARNING:tweepy.api:Unexpected parameter: end_datetime\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "import csv\n",
        "\n",
        "# Mengisi API key dan token Twitter\n",
        "consumer_key = 'DqsKCoLOziEpR3OMH5Y8oiz7c'\n",
        "consumer_secret = 'OHljrypY8YoxqQhvqj0PZAir379j8VUHBvvC5KMiqrJnQtpq9V'\n",
        "access_token = '1561941875782610944-2c3p2Fn97uatF6NnmDmD9HLD4vtr8T'\n",
        "access_token_secret = 'UbGxV1KgCAlc22fGI2febtfvLgNjwF0H8crFv2vdzei5z'\n",
        "\n",
        "# Mengotentikasi dengan Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Kata kunci dan tanggal yang ingin dicari\n",
        "keyword = 'ganjar 2024 -filter:retweets'\n",
        "start_date = '2023-05-01'\n",
        "end_date = '2023-05-31'\n",
        "\n",
        "# Jumlah tweet yang ingin diambil\n",
        "tweet_count = 250\n",
        "\n",
        "# Melakukan crawling\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=keyword, lang='id', start_datetime=start_date, end_datetime=end_date, tweet_mode='extended').items(tweet_count)\n",
        "\n",
        "# Menyimpan hasil crawling ke dalam file CSV\n",
        "with open('Ganjar2024Mei.csv', 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Tanggal', 'Username', 'Tweet'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        writer.writerow([tweet.created_at, tweet.user.screen_name, tweet.full_text])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWlCTZzm6JLc"
      },
      "source": [
        "# KODE LAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "6M68HzL46Ite",
        "outputId": "87c40d74-4da1-4cd4-ed3a-912d1f8fa686"
      },
      "outputs": [
        {
          "ename": "TooManyRequests",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-36233dd82fef>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mtweet_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             model = ModelParser().parse(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m_Twitter\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \"\"\"\n\u001b[0;32m-> 1309\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             'GET', 'search/tweets', endpoint_parameters=(\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geocode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'locale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m429\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTooManyRequests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTwitterServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 Too Many Requests\n88 - Rate limit exceeded"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import tweepy\n",
        "from datetime import datetime\n",
        "\n",
        "consumer_key = 'DqsKCoLOziEpR3OMH5Y8oiz7c'\n",
        "consumer_secret = 'OHljrypY8YoxqQhvqj0PZAir379j8VUHBvvC5KMiqrJnQtpq9V'\n",
        "access_token = '1561941875782610944-2c3p2Fn97uatF6NnmDmD9HLD4vtr8T'\n",
        "access_token_secret = 'UbGxV1KgCAlc22fGI2febtfvLgNjwF0H8crFv2vdzei5z'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# kata kunci\n",
        "keyword = 'ganjar 2024 -filter:retweets'\n",
        "\n",
        "# Tanggal awal dan akhir yang ingin Anda ambil data-nya\n",
        "start_date = datetime.strptime(\"2023-05-01\", \"%Y-%m-%d\").date()\n",
        "end_date = datetime.strptime(\"2023-05-31\", \"%Y-%m-%d\").date()\n",
        "# start_date = \"2023-05-01\"\n",
        "# end_date = \"2023-05-31\"\n",
        "\n",
        "max_tweets = 1000\n",
        "tweets = []\n",
        "count = 0\n",
        "\n",
        "for tweet in tweepy.Cursor(api.search_tweets, q=keyword).items():\n",
        "    tweet_date = tweet.created_at.date()\n",
        "\n",
        "    if start_date <= tweet_date <= end_date:\n",
        "        tweets.append(tweet)\n",
        "        count += 1\n",
        "\n",
        "        if count >= max_tweets:\n",
        "            break\n",
        "\n",
        "# Simpan data tweet dalam file CSV\n",
        "filename = \"Ganjar_Mei.csv\"\n",
        "\n",
        "with open(filename, \"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Tanggal', 'Username', 'Tweet'])\n",
        "\n",
        "    for tweet in tweets:\n",
        "        writer.writerow([tweet.created_at, tweet.user.screen_name, tweet.full_text])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihlI1UCaFx_f"
      },
      "source": [
        "# KODE Youtube **Terbaru**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7ndKMLkSjfQ"
      },
      "source": [
        "## Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otqiL7b7IBP4",
        "outputId": "78927857-4197-49a2-8166-6ac3509ded45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
            "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /tmp/pip-req-build-x8ytgoq9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/JustAnotherArchivist/snscrape.git /tmp/pip-req-build-x8ytgoq9\n",
            "  Resolved https://github.com/JustAnotherArchivist/snscrape.git to commit 614d4c2029a62d348ca56598f87c425966aaec66\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (2.27.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from snscrape==0.7.0.20230622) (3.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->snscrape==0.7.0.20230622) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape==0.7.0.20230622) (1.7.1)\n",
            "Building wheels for collected packages: snscrape\n",
            "  Building wheel for snscrape (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for snscrape: filename=snscrape-0.7.0.20230622-py3-none-any.whl size=74814 sha256=a697520821c1850a248e27e768fd1b667149d2c2a018aff2340f5c6f0d581ccd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q6d81e9_/wheels/05/e9/f7/57056e7c7e44b1feed932fa49fdec9d706c4f563e37160ab74\n",
            "Successfully built snscrape\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.7.0.20230622\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade git+https://github.com/JustAnotherArchivist/snscrape.git\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDrsvMUKSx8g"
      },
      "source": [
        "## kode crawling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWgwcgg5-Job",
        "outputId": "9bb7dc30-fd97-4ac9-e603-9e44c1ec4af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "snscrape --jsonl --max-results 1000 twitter-search  'prabowo lang:id until:2023-05-31 since:2023-05-01' > prabowo_lang-id_until-2023-05-31_since-2023-05-01_2023-07-07.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "# Batasi jumlah hasil yang diambil\n",
        "max_results = 1000\n",
        "\n",
        "# Gunakan Twitter search untuk mencari tweet yang di-favoritkan minimal 10000 kali dan berbahasa Indonesia\n",
        "twitter_search = \"prabowo lang:id until:2023-05-31 since:2023-05-01\"\n",
        "\n",
        "# Tentukan nama file dengan format \"<kueri pencarian>_<tanggal saat ini>.json\"\n",
        "filename = f\"{twitter_search.replace(' ', '_').replace(':', '-').replace('#', '')}_{datetime.date.today().strftime('%Y-%m-%d')}.json\"\n",
        "\n",
        "USING_TOP_SEARCH = False\n",
        "\n",
        "snscrape_params = '--jsonl --max-results'\n",
        "twitter_search_params = ''\n",
        "\n",
        "if USING_TOP_SEARCH:\n",
        "    twitter_search_params += \"--top\"\n",
        "\n",
        "snscrape_search_query = f\"snscrape {snscrape_params} {max_results} twitter-search {twitter_search_params} '{twitter_search}' > {filename}\"\n",
        "\n",
        "print(snscrape_search_query)\n",
        "\n",
        "os.system(snscrape_search_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gCsYXlQS4Oe"
      },
      "source": [
        "## menyimpan data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSfiYhhmIiVX",
        "outputId": "a650d4cb-360d-43eb-a14c-b8b96bab716e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pencarian tidak ditemukan coba ganti keyword lain, keywordmu:  prabowo lang:id until:2023-05-31 since:2023-05-01\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import json\n",
        "\n",
        "# Membaca file JSON hasil dari perintah CLI sebelumnya dan membuat dataframe pandas\n",
        "tweets_df = pd.read_json(filename, lines=True)\n",
        "\n",
        "NAMA_FILE_CSV = 'prabowo.csv'\n",
        "\n",
        "# Membuat kamus untuk mengganti nama kolom\n",
        "new_columns = {\n",
        "    'date': 'Date',\n",
        "    'username': 'Username',\n",
        "    'rawContent': 'Tweet',\n",
        "\n",
        "}\n",
        "\n",
        "if len(tweets_df) == 0:\n",
        "    print('Pencarian tidak ditemukan coba ganti keyword lain, keywordmu: ', twitter_search)\n",
        "    exit()\n",
        "else:\n",
        "  # Memilih kolom yang akan digunakan dan mengganti nama kolom menggunakan kamus yang telah dibuat\n",
        "  tweets_df = tweets_df.loc[:, ['date', 'username', 'rawContent']]\n",
        "  tweets_df = tweets_df.rename(columns=new_columns)\n",
        "\n",
        "  # Menampilkan dataframe tweets_df\n",
        "  display(tweets_df)\n",
        "\n",
        "  # Simpan ke csv\n",
        "  tweets_df.to_csv(NAMA_FILE_CSV, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y766U0q3TsM9"
      },
      "source": [
        "## chatgpt *snscrape* **Fixxx**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "JavP3pdTGCvl",
        "outputId": "74c816ff-07bd-40c2-ec0b-7432508ecb35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:snscrape.base:Error retrieving https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22prabowo%20since%3A2023-06-01%20until%3A2023-06-30%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D: blocked (404)\n",
            "CRITICAL:snscrape.base:4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22prabowo%20since%3A2023-06-01%20until%3A2023-06-30%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_rich_text_read_enabled%22%3Afalse%2C%22longform_notetweets_inline_media_enabled%22%3Afalse%2C%22responsive_web_enhance_cards_enabled%22%3Afalse%2C%22responsive_web_twitter_blue_verified_badge_is_enabled%22%3Atrue%7D failed, giving up.\n",
            "CRITICAL:snscrape.base:Errors: blocked (404), blocked (404), blocked (404), blocked (404)\n"
          ]
        },
        {
          "ename": "ScraperException",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mScraperException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1d30e2a7a555>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Melakukan crawling data tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterSearchScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{search_query} since:{start_date} until:{end_date}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36mget_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 \u001b[0mpaginationParams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'variables'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpaginationVariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'features'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1763\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaginationParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'search_by_raw_query'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'search_timeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'timeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'instructions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1764\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graphql_timeline_instructions_to_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search_by_raw_query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search_timeline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timeline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instructions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_iter_api_data\u001b[0;34m(self, endpoint, apiType, params, paginationParams, cursor, direction, instructionsPath)\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Retrieving scroll page {cursor}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapiType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreqParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstructionsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_get_api_data\u001b[0;34m(self, endpoint, apiType, params, instructionsPath)\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mapiType\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote_via\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apiHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseOkCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_api_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapiType\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapiType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstructionsPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstructionsPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_snscrapeObj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Errors: {\", \".join(errors)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mScraperException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reached unreachable code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mScraperException\u001b[0m: 4 requests to https://twitter.com/i/api/graphql/7jT5GT59P8IFjgxwqnEdQw/SearchTimeline?variables=%7B%22rawQuery%22%3A%22prabowo%20since%3A2023-06-01%20until%3A2023-06-30%22%2C%22count%22%3A20%2C%22product%22%3A%22Latest%22%2C%22withDownvotePerspective%22%3Afalse%2C%22withReactionsMetadata%22%3Afalse%2C%22withReactionsPerspective%22%3Afalse%7D&features=%7B%22rweb_lists_timeline_redesign_enabled%22%3Afalse%2C%22blue_business_profile_image_shape_enabled%22%3Afalse%2C%22responsive_web_graphql_exclude_directive_enabled%22%3Atrue%2C%22verified_phone_label_enabled%22%3Afalse%2C%22creator_subscriptions_tweet_preview_api_enabled%22%3Afalse%2C%22responsive_web_graphql_timeline_navigation_enabled%22%3Atrue%2C%22responsive_web_graphql_skip_user_profile_image_extensions_enabled%22%3Afalse%2C%22tweetypie_unmention_optimization_enabled%22%3Atrue%2C%22vibe_api_enabled%22%3Atrue%2C%22responsive_web_edit_tweet_api_enabled%22%3Atrue%2C%22graphql_is_translatable_rweb_tweet_is_translatable_enabled%22%3Atrue%2C%22view_counts_everywhere_api_enabled%22%3Atrue%2C%22longform_notetweets_consumption_enabled%22%3Atrue%2C%22tweet_awards_web_tipping_enabled%22%3Afalse%2C%22freedom_of_speech_not_reach_fetch_enabled%22%3Afalse%2C%22standardized_nudges_misinfo%22%3Atrue%2C%22tweet_with_visibility_results_prefer_gql_limited_actions_policy_enabled%22%3Afalse%2C%22interactive_text_enabled%22%3Atrue%2C%22responsive_web_text_conversations_enabled%22%3Afalse%2C%22longform_notetweets_r..."
          ]
        }
      ],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import csv\n",
        "\n",
        "# Tanggal awal dan akhir untuk pencarian tweet\n",
        "start_date = \"2023-06-01\"\n",
        "end_date = \"2023-06-30\"\n",
        "\n",
        "# Jumlah tweet yang ingin diambil\n",
        "num_tweets = 1000\n",
        "\n",
        "# Kata kunci pencarian\n",
        "search_query = \"prabowo\"\n",
        "\n",
        "# Membuka file CSV untuk menyimpan data tweet\n",
        "with open('tweets.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Date', 'Username', 'Text'])\n",
        "\n",
        "    # Melakukan crawling data tweet\n",
        "    for tweet in sntwitter.TwitterSearchScraper(f'{search_query} since:{start_date} until:{end_date}').get_items():\n",
        "        writer.writerow([tweet.date, tweet.user.username, tweet.content])\n",
        "\n",
        "        # Berhenti jika sudah mencapai jumlah tweet yang diinginkan\n",
        "        if tweet.counter >= num_tweets:\n",
        "            break\n",
        "\n",
        "print(\"Crawling selesai. Data tweet disimpan dalam file tweets.csv\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}